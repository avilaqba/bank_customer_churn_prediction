{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Customer Churn Analysis on a Banking Dataset","metadata":{}},{"cell_type":"markdown","source":"### Data Cleaning and Preprocessing ","metadata":{}},{"cell_type":"code","source":"# Reading the dataset\nimport pandas as pd\ndata = pd.read_csv('../input/churn-for-bank-customers/churn.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:16.175221Z","iopub.execute_input":"2021-06-30T11:25:16.175791Z","iopub.status.idle":"2021-06-30T11:25:16.262324Z","shell.execute_reply.started":"2021-06-30T11:25:16.175753Z","shell.execute_reply":"2021-06-30T11:25:16.261172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the unnecessary columns\ndata = data.drop(['RowNumber','CustomerId','Surname'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:20.60851Z","iopub.execute_input":"2021-06-30T11:25:20.608889Z","iopub.status.idle":"2021-06-30T11:25:20.616535Z","shell.execute_reply.started":"2021-06-30T11:25:20.608859Z","shell.execute_reply":"2021-06-30T11:25:20.615033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cheking for missing values in the dataset\ndata.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:22.035373Z","iopub.execute_input":"2021-06-30T11:25:22.035722Z","iopub.status.idle":"2021-06-30T11:25:22.048312Z","shell.execute_reply.started":"2021-06-30T11:25:22.035693Z","shell.execute_reply":"2021-06-30T11:25:22.046871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that in this dataset there are no missing values.","metadata":{}},{"cell_type":"code","source":"# Cheking the types of data in columns\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:24.891316Z","iopub.execute_input":"2021-06-30T11:25:24.891656Z","iopub.status.idle":"2021-06-30T11:25:24.901484Z","shell.execute_reply.started":"2021-06-30T11:25:24.891627Z","shell.execute_reply":"2021-06-30T11:25:24.899827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hereby, the categorical columns are being handled. Note that we may also use the get_dummies method instead.","metadata":{}},{"cell_type":"code","source":"# Appying the label encoding technique on categorical columns\ndata['Geography'] = data['Geography'].astype('category').cat.codes\ndata['Gender'] = data['Gender'].astype('category').cat.codes\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:27.505546Z","iopub.execute_input":"2021-06-30T11:25:27.50589Z","iopub.status.idle":"2021-06-30T11:25:27.523365Z","shell.execute_reply.started":"2021-06-30T11:25:27.505862Z","shell.execute_reply":"2021-06-30T11:25:27.52224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specifying the features and target\nX = data.drop(columns = ['Exited'])\ny = data.Exited","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:28.707969Z","iopub.execute_input":"2021-06-30T11:25:28.708354Z","iopub.status.idle":"2021-06-30T11:25:28.71541Z","shell.execute_reply.started":"2021-06-30T11:25:28.708321Z","shell.execute_reply":"2021-06-30T11:25:28.714208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Handling Highly Correlated Features","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Calculating correlation of features to one another\ncorr = X.corr().abs()\ncorr = corr.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:32.757777Z","iopub.execute_input":"2021-06-30T11:25:32.75831Z","iopub.status.idle":"2021-06-30T11:25:32.769874Z","shell.execute_reply.started":"2021-06-30T11:25:32.758277Z","shell.execute_reply":"2021-06-30T11:25:32.768984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the correlation matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot = True, annot_kws={'size':12})\nheat_map=plt.gcf()\nheat_map.set_size_inches(20,15)\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\nplt.savefig(\"corr.png\", dpi=100)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:35.801046Z","iopub.execute_input":"2021-06-30T11:25:35.801563Z","iopub.status.idle":"2021-06-30T11:25:38.158712Z","shell.execute_reply.started":"2021-06-30T11:25:35.801532Z","shell.execute_reply":"2021-06-30T11:25:38.157807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the upper triangle of the correlation matrix\nupper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n# Finding the index of feature columns with correlation greater than 0.9\nDrop = [column for column in upper.columns if any(upper[column] > 0.9)][:-1]\n# Eliminating one of each pair of features with correlation greater than 0.90\nX = X.drop(X[Drop], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:39.978457Z","iopub.execute_input":"2021-06-30T11:25:39.978858Z","iopub.status.idle":"2021-06-30T11:25:40.010762Z","shell.execute_reply.started":"2021-06-30T11:25:39.978825Z","shell.execute_reply":"2021-06-30T11:25:40.009657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that in the case of this dataset, there were no pair of features with correlation greater than 0.9. Thus, no feature has been eliminated.","metadata":{}},{"cell_type":"markdown","source":"### Model Selection and Hyperparameter Optimization utilizing Five Classification Algorithms","metadata":{}},{"cell_type":"code","source":"# Splitting the data into train and test sets\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:45.922943Z","iopub.execute_input":"2021-06-30T11:25:45.923673Z","iopub.status.idle":"2021-06-30T11:25:46.18548Z","shell.execute_reply.started":"2021-06-30T11:25:45.923615Z","shell.execute_reply":"2021-06-30T11:25:46.184291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Specifying the models and hyperparameter sets for each\n\npipe1 = Pipeline([['sc',sc],['clf1',KNeighborsClassifier()]])\nparams_1 = [{'clf1__n_neighbors': [1,3, 5, 7, 9,11,13,15],'clf1__leaf_size': [10, 15, 20, 25],'clf1__weights': ['uniform', 'distance']}]\n\npipe2 = Pipeline([['sc',sc],['clf2',LinearSVC()]])\nparams_2 = {'clf2__penalty':['l1','l2'],'clf2__C': [0.001, 0.01, 0.1, 1, 10],'clf2__loss':('hinge','squared_hinge')}\n\npipe3 = Pipeline([['sc',sc],['clf3',LogisticRegression(random_state=42)]])\nparams_3={'clf3__penalty':['l1','l2'],'clf3__C':np.logspace(-4, 4, 20)}\n\npipe4 = Pipeline([['sc',sc],['clf4',DecisionTreeClassifier(random_state=42)]])\nparams_4 = {'clf4__max_depth':[3,4,5,6,7,8,9,10,12,15,20,30,45,60,90,130],'clf4__criterion':['gini','entropy']}\n\npipe5 = Pipeline([['sc',sc],['clf5',RandomForestClassifier()]])\nparams_5 = {'clf5__min_samples_leaf': [1, 2, 4], 'clf5__n_estimators': [50,200, 700],'clf5__max_features': ['auto', 'sqrt', 'log2'],'clf5__min_samples_split': [2, 5, 10]}\n\nclassifiers = ['KNN','LinearSVC' ,'Logistic Regression', 'Decision Tree','RandomForestClassifier']","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:47.341855Z","iopub.execute_input":"2021-06-30T11:25:47.342409Z","iopub.status.idle":"2021-06-30T11:25:47.614017Z","shell.execute_reply.started":"2021-06-30T11:25:47.342368Z","shell.execute_reply":"2021-06-30T11:25:47.613088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nfor clf_name, clf, params in zip(classifiers, [pipe1,pipe2,pipe3,pipe4,pipe5], [params_1,params_2,params_3,params_4,params_5]):\n    # Doing the grid search on each model\n    grid_search=GridSearchCV(clf, params, n_jobs=-1, verbose=0,cv=5)\n    grid_search.fit(X_train, y_train)\n    print('â”€'*100)\n    print('\\033[1mGrid search on %s\\033[0m'%clf_name)\n    # Getting the best score\n    best_score = grid_search.best_score_\n    print('The best score: %.2f'%best_score)\n    # Getting the set of best parameters\n    best_parameters = grid_search.best_params_\n    print('The best set of parameters:')\n    for param_name in best_parameters.keys():\n        print('\\t%s: %s'%(param_name,best_parameters[param_name]))\n    print('\\n\\033[1m5-fold cross-validation\\033[0m')\n    print('\\t\\t\\t      train  test')\n    estimator = clf.set_params(**best_parameters)\n    # 5-fold cross-validation on train and test sets using the best paramters set\n    for scoring in ['accuracy','f1','roc_auc','precision','recall']:\n        scores_train=cross_val_score(estimator=estimator, X=X_train,y=y_train.ravel(), cv=5, scoring=scoring)\n        scores_test=cross_val_score(estimator=estimator, X=X_test,y=y_test.ravel(), cv=5, scoring=scoring)\n        print(f\"\\t{scoring:20}  {scores_train.mean():.2f}   {scores_test.mean():.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:25:50.724618Z","iopub.execute_input":"2021-06-30T11:25:50.725019Z","iopub.status.idle":"2021-06-30T11:33:58.852671Z","shell.execute_reply.started":"2021-06-30T11:25:50.724977Z","shell.execute_reply":"2021-06-30T11:33:58.851284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Conclusion on Model Selection\nSince the roc_auc score is the most widely considered metrics for binary classification, considering the results of roc_auc, the RandomForestClassifier seems to be the best model to pick with roc_auc scores of 0.85 and 0.84 on train and test sets, respectively. Beside as shown above, the best parameter set that we have found can be used for this model.","metadata":{}},{"cell_type":"markdown","source":"### Feature Selection using Three Different Methods","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif , SelectKBest\nfrom sklearn.feature_selection import RFE\n\n# Using the RandomForestClassifier to get the feature importances in order to rank the features\nrf = RandomForestClassifier()\nrf.fit(X, y)\nfeature_importances = pd.DataFrame(rf.feature_importances_, index = X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\nprint ('Selected top features using feature importance in a RandomForestClassifier:')\nprint (list(feature_importances.index[:4]))\nprint (' ')\n\n# Defining the feature selection method using mutual info classification in order to get the top 4, then fitting the data\nselector = SelectKBest(score_func=mutual_info_classif)\nselector.fit_transform(X, y)\n\n# Getting the indices of the top 4 features and printing the names\ncols = selector.get_support(indices=True)\nprint ('Selected features having top mutual information scores:')\nprint (list(X_train.iloc[:,cols].columns)[:4])\nprint (' ')\n# Using recursive feature elimination method in order to get the top 4 features\nrfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=4)\nrfe.fit(X, y)\n\n# Getting the indices of the top 4 features and printing the names\ntop_4 = np.array(list(X_train.columns))[rfe.support_]\nprint ('Selected features by Recrucive Feature Elimination:')\nprint(top_4)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:34:52.273782Z","iopub.execute_input":"2021-06-30T11:34:52.274206Z","iopub.status.idle":"2021-06-30T11:34:54.74403Z","shell.execute_reply.started":"2021-06-30T11:34:52.274157Z","shell.execute_reply":"2021-06-30T11:34:54.742861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Overfit and Underfit Analysis","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n# Using the learning_curve module with LogisticRegression as the model\nlog_reg = LogisticRegression()\nlrn_crv = learning_curve(log_reg, X, y, scoring='roc_auc', cv=5, train_sizes=np.array([0.1, 0.2, 0.3, 0.4,0.5,0.6,0.7,0.8,0.9,1.0]))\nlrn_crv","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:34:58.297211Z","iopub.execute_input":"2021-06-30T11:34:58.297664Z","iopub.status.idle":"2021-06-30T11:35:02.670348Z","shell.execute_reply.started":"2021-06-30T11:34:58.297601Z","shell.execute_reply":"2021-06-30T11:35:02.668574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrains, tests = [], []\nfor i,j in zip(lrn_crv[1],lrn_crv[2]):\n    trains.append(np.mean(i))\n    tests.append(np.mean(j))\n# Plotting the ROC AUC curve for different number of training examples for the purpose of overfit/underfit analysis \nplt.plot(lrn_crv[0],trains, '-o')\nplt.plot(lrn_crv[0],tests, '-v')\nplt.grid(True)\nplt.xlabel('Number of Training Examples')\nplt.ylabel('ROC AUC')\nplt.legend(['Training Score', 'Test Score'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T11:35:04.546667Z","iopub.execute_input":"2021-06-30T11:35:04.547051Z","iopub.status.idle":"2021-06-30T11:35:04.74541Z","shell.execute_reply.started":"2021-06-30T11:35:04.54702Z","shell.execute_reply":"2021-06-30T11:35:04.744423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Interpretation\nAs seen in the figure above, if we split the data evenly into train and test splits (50%; each), we would not have a good score for neither of the train and test sets, and we will have an underfit due to the slightly better score of the test set. \nOn the other hand, if we consider around 10% of the data for the training set, we would have an overfit model, since the model will memorize the small amount of data; thus it will not perform well on the test set.\nNote that in the figure above, if around 70% would be considered as the training set, the model, in this case logistic regression, would perform well.\nThis also validates our initial train_test_split above before using the five algorithms.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}